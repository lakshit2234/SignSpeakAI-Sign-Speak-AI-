SignSpeakAI â€“ Bridging Speech & Sign Language with AI
ğŸŒŸ Overview
SignSpeakAI is an AI-powered system designed to enhance communication between speech and sign language users. It integrates real-time gesture recognition, Speech-to-Sign (STS), and Text-to-Speech (TTS) using deep learning techniques. The system enables seamless translation between spoken words and sign gestures, improving accessibility for the deaf and hard-of-hearing communities.

ğŸš€ Features
âœ” Real-time Hand Gesture Recognition â€“ Uses MediaPipe & LSTM-based deep learning model
âœ” Speech-to-Sign Conversion (STS) â€“ Converts spoken words into corresponding sign images
âœ” Text-to-Speech (TTS) â€“ Converts text input into natural-sounding speech
âœ” Multilingual Support â€“ Recognizes and translates speech across different languages
âœ” User-Friendly Interface â€“ Provides an intuitive and interactive experience

ğŸ— Implementation
Hand Gesture Recognition: Utilizes MediaPipe Hands to extract hand landmarks and classify gestures using an LSTM model trained on custom datasets.

Speech-to-Sign (STS): Recognizes speech with SpeechRecognition and maps words to sign images.

Text-to-Speech (TTS): Converts text into audio using gTTS and plays it with Pygame.

ğŸ›  Tech Stack & Libraries
ğŸ”¹ Python â€“ Core programming language
ğŸ”¹ TensorFlow/Keras â€“ Deep learning model for gesture recognition
ğŸ”¹ OpenCV â€“ Real-time video processing
ğŸ”¹ MediaPipe â€“ Hand landmark detection
ğŸ”¹ SpeechRecognition â€“ Converts spoken words into text
ğŸ”¹ gTTS (Google Text-to-Speech) â€“ Converts text into speech
ğŸ”¹ Pygame â€“ Plays generated speech audio
